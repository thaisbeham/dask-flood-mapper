{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://gateway.dask.org/_static/images/dask-horizontal-white.svg\"\n",
    "     alt=\"Dask Logo\"\n",
    "     style=\"margin-right: 10px; width: 50%\" />\n",
    "# Distributed computing with Dask\n",
    "\n",
    "EODC offers Dask as service by utilising [Dask Gateway](https://gateway.dask.org/). User can launch a Dask cluster in a shared and managed cluster environment without requring to have direct access to any cloud infrastructure resources such as VMs or Kubernetes clusters. The objetive is to lower the entrance barrier for users to run large scale data analysis on demand and in a scaleable environment.\n",
    "\n",
    "An generic introduction of the usage of Dask Gateway can be found on the official [Dask Gateway documentation](https://gateway.dask.org/usage.html). In the following we will demonstrate the use of the Dask service at EODC to further support users.\n",
    "\n",
    "Pre-requisit is to have Dask Gateway installed in your environment\n",
    "```bash\n",
    "pip install dask-gateway\n",
    "```\n",
    "or \n",
    "```bash\n",
    "conda install -c conda-forge dask-gateway\n",
    "```\n",
    "\n",
    "It is important to note that the Python environment running the code and the environment utilised by Dask Gateway have to be almost identical.\n",
    "\n",
    "We will install some additional packages used in this demo afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication via OIDC password grant flow\n",
    "Only authenticated access is granted to the EODC Dask service, therefore a helper class to authenticate a user against the EODC identifiy managment system is implemented in the [EODC SDK](https://github.com/eodcgmbh/eodc-sdk).\n",
    "The users password is directly handed over to the request object and is not stored.\n",
    "Refreshed token is used to request a new access token in case it is expired, which is handled automatically in the authenticator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to EODC Dask\n",
    "\n",
    "Authenticating and connecting to EODC Dask can be done with a few lines of Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following in order to make sure all dependencies are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Enter your Username: </pre>\n"
      ],
      "text/plain": [
       "Enter your Username: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'access_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m console \u001b[38;5;241m=\u001b[39m Console()\n\u001b[1;32m      5\u001b[0m your_username \u001b[38;5;241m=\u001b[39m Prompt\u001b[38;5;241m.\u001b[39mask(prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your Username\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m gateway \u001b[38;5;241m=\u001b[39m \u001b[43mEODCDaskGateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myour_username\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/eodc/dask.py:13\u001b[0m, in \u001b[0;36mEODCDaskGateway.__init__\u001b[0;34m(self, username)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, username: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauthenticator \u001b[38;5;241m=\u001b[39m \u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDaskOIDC\u001b[49m\u001b[43m(\u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musername\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     15\u001b[0m         address\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mDASK_URL,\n\u001b[1;32m     16\u001b[0m         proxy_address\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mDASK_URL_TCP,\n\u001b[1;32m     17\u001b[0m         auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauthenticator,\n\u001b[1;32m     18\u001b[0m     )\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/eodc/auth.py:18\u001b[0m, in \u001b[0;36mDaskOIDC.__init__\u001b[0;34m(self, username)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_url \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mKEYCLOAK_CERT_URL\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccess_token_decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_access_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/eodc/auth.py:33\u001b[0m, in \u001b[0;36mDaskOIDC.decode_access_token\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m jwks_client \u001b[38;5;241m=\u001b[39m PyJWKClient(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_url)\n\u001b[1;32m     32\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m signing_key \u001b[38;5;241m=\u001b[39m jwks_client\u001b[38;5;241m.\u001b[39mget_signing_key_from_jwt(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccess_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     34\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_token\u001b[39m\u001b[38;5;124m\"\u001b[39m], signing_key\u001b[38;5;241m.\u001b[39mkey, algorithms\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRS256\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'access_token'"
     ]
    }
   ],
   "source": [
    "from eodc.dask import EODCDaskGateway\n",
    "from rich.console import Console\n",
    "from rich.prompt import Prompt\n",
    "console = Console()\n",
    "your_username = Prompt.ask(prompt=\"Enter your Username\")\n",
    "gateway = EODCDaskGateway(username=your_username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Cluster configuration if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f223d9aa16e14f42ae7b18a558dfb5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Cluster Options</h2>'), GridBox(children=(HTML(value=\"<p style='font-weight: boâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options<worker_cores=2,\n",
      "        worker_memory=2.0,\n",
      "        image='registry.eodc.eu/eodc/clusters/dedl-deployment/dedl-dask:2023.08.3'>\n"
     ]
    }
   ],
   "source": [
    "cluster_options = gateway.cluster_options()\n",
    "cluster_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dask Cluster\n",
    "\n",
    "Now we are going to create a Dask Cluster in order to run compute jobs.\n",
    "To communicate with the cluster we have to instantiate a client as well.\n",
    "Per default, no worker nodes are spawned, but this can be done either manually or even by enabling adaptive scaling of the cluster.\n",
    "\n",
    "**Important: Please use the widget to add/scale the Dask workers. Per default no worker is spawned, therefore no computations can be performed by the cluster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cluster \u001b[38;5;241m=\u001b[39m \u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m cluster\u001b[38;5;241m.\u001b[39mget_client()\n\u001b[1;32m      3\u001b[0m cluster\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/dask_gateway/client.py:641\u001b[0m, in \u001b[0;36mGateway.new_cluster\u001b[0;34m(self, cluster_options, shutdown_on_close, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_cluster\u001b[39m(\u001b[38;5;28mself\u001b[39m, cluster_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shutdown_on_close\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    619\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Submit a new cluster to the gateway, and wait for it to be started.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m    Same as calling ``submit`` and ``connect`` in one go.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    cluster : GatewayCluster\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGatewayCluster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublic_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_public_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshutdown_on_close\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/dask_gateway/client.py:816\u001b[0m, in \u001b[0;36mGatewayCluster.__init__\u001b[0;34m(self, address, proxy_address, public_address, auth, cluster_options, shutdown_on_close, asynchronous, loop, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    806\u001b[0m     address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    815\u001b[0m ):\n\u001b[0;32m--> 816\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublic_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpublic_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcluster_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcluster_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshutdown_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshutdown_on_close\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/dask_gateway/client.py:921\u001b[0m, in \u001b[0;36mGatewayCluster._init_internal\u001b[0;34m(self, address, proxy_address, public_address, auth, cluster_options, cluster_kwargs, shutdown_on_close, asynchronous, loop, name)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masynchronous:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_internal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/dask-flood-mapper/dask-flood-mapper/.venv/lib/python3.10/site-packages/dask_gateway/client.py:344\u001b[0m, in \u001b[0;36mGateway.sync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(\n\u001b[1;32m    341\u001b[0m     func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39masyncio_loop\n\u001b[1;32m    342\u001b[0m )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     future\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cluster = gateway.new_cluster(cluster_options)\n",
    "client = cluster.get_client()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to spawn a workers directly via Python adaptively please use the following method call. With the following the cluster will be scaled to 2 workers initially.\n",
    "Depending on the load, Dask will add addtional workers, up to 5, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=2, maximum=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List clusters if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "console.print(gateway.list_clusters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can connect to already running clusters again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.connect(gateway.list_clusters()[0].name)\n",
    "console.print(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Dask Dashboard to monitor execution of computations\n",
    "Copy the following link into a browser of your choice. Please consider the dashboard url provided is making use of http and not https."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import xarray as xr\n",
    "\n",
    "s3fs_central = s3fs.S3FileSystem(\n",
    "    anon=True,\n",
    "    use_ssl=True,\n",
    "    client_kwargs={\"endpoint_url\": \"https://s3.central.data.destination-earth.eu\"})\n",
    "\n",
    "s3fs_lumi = s3fs.S3FileSystem(\n",
    "    anon=True,\n",
    "    use_ssl=True,\n",
    "    client_kwargs={\"endpoint_url\": \"https://s3.lumi.data.destination-earth.eu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3fs_central.ls(\"increment1-testdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data stored in S3 bucket at central site (Poland).\n",
    "The data we want to read is a single Zarr data store representing GFM flood data over Pakistan for 2022-08-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flood_map = xr.open_zarr(store=s3fs.S3Map(root=f\"increment1-testdata/2022-08-30.zarr\", s3=s3fs_central, check=False),\n",
    "                         decode_coords=\"all\",)[\"flood\"].assign_attrs(location=\"central\", resolution=20)\n",
    "flood_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run simple computation and compute the flooded area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flooded_area_ = flood_map.sum()*20*20/1000.\n",
    "flooded_area_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we haven't computed anything, so lets do the computation now on the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flooded_area = client.compute(flooded_area_, sync=True)\n",
    "console.print(f\"Flooded area: {flooded_area.data}km2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data stored in S3 bucket at LUMI bridge (Finland).\n",
    "Data we want to read is a datacube generated from ERA-5 representing predicted rainfall data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rainfall = xr.open_zarr(store=s3fs.S3Map(root=f\"increment1-testdata/predicted_rainfall.zarr\",\n",
    "                                         s3=s3fs_lumi,\n",
    "                                         check=False),\n",
    "                        decode_coords=\"all\",)[\"tp\"].assign_attrs(location=\"lumi\", resolution=20)\n",
    "rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from attr import dataclass\n",
    "\n",
    "def accum_rain_predictions(rain_data, startdate, enddate, extent):\n",
    "    rain_ = rain_data.sel(time=slice(startdate, enddate),\n",
    "                          latitude=slice(extent.max_y, extent.min_y),\n",
    "                          longitude=slice(extent.min_x, extent.max_x))\n",
    "    return rain_.cumsum(dim=\"time\", keep_attrs=True)*1000\n",
    "\n",
    "@dataclass\n",
    "class Extent:\n",
    "    min_x: float\n",
    "    min_y: float\n",
    "    max_x: float\n",
    "    max_y: float\n",
    "    crs: str\n",
    "\n",
    "# compute accumulated rainfall over Pakistan\n",
    "roi_extent = Extent(65, 21, 71, 31, crs='EPSG:4326')\n",
    "acc_rain_ = accum_rain_predictions(rainfall, startdate=datetime(2022, 8, 18),\n",
    "                                             enddate=datetime(2022, 8, 30),\n",
    "                                             extent=roi_extent)\n",
    "\n",
    "# compute average rainfall for August 2022\n",
    "rain_ = rainfall.sel(time=slice(datetime(2022, 8, 1), datetime(2022, 8, 30))).mean(dim=\"time\", keep_attrs=True)*1000\n",
    "rain_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again run the computation on our EODC Dask cluster.\n",
    "First we compute the accumulated rainfall over Pakistan.\n",
    "Secondly we compute the average rainfall for August 2022 (monthly mean) at global scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_rain = client.compute(acc_rain_, sync=True)\n",
    "acc_rain\n",
    "mean_rain = client.compute(rain_, sync=True)\n",
    "mean_rain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the accumlated rainfall computed for Pakistan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rain.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.close(shutdown=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
