{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Flood Mapping\n",
    "\n",
    "Besides processing of a flood's extent on your own machine one can also offload the processing graph to the EODC Dask Gateway. \n",
    "\n",
    "This notebook is based on the tutorial to connect to EODC Dask available at [this link](https://github.com/eodcgmbh/eodc-examples/blob/main/demos/dask.ipynb).\n",
    "\n",
    "More information about EODC Dask Gateway can be found [here](https://docs.eodc.eu/services/dask.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to EODC Dask\n",
    "\n",
    "Autentication is required through an username and password that should be requested to EODC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eodc.dask import EODCDaskGateway\n",
    "from rich.console import Console\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "console = Console()\n",
    "your_username = Prompt.ask(prompt=\"Enter your Username\")\n",
    "gateway = EODCDaskGateway(username=your_username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Configuration\n",
    "\n",
    "It is possible to change the default configuration to optimize your specifications at the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_options = gateway.cluster_options()\n",
    "cluster_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dask Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate a client\n",
    "In order to create a Dask cluster, it is first necessary to initiate the client. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important:</b> Per default no worker is spawned, therefore please use the widget to add/scale Dask workers in other to enable compuations on the cluster.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster(cluster_options)\n",
    "client = cluster.get_client()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to spawn workers is trhough the cell below that sets two workers as starting point and enables up to 5 workers, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=2, maximum=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List available clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(gateway.list_clusters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to already running clusters \n",
    "\n",
    "Instead of restarting the whole process again, you can directly connect to cluster already running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.connect(gateway.list_clusters()[0].name)\n",
    "console.print(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask dashboard\n",
    "\n",
    "The following link displays the Dask Dashboard that can be used to monitor the execution of computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Dask Flood Mapping\n",
    "\n",
    "Uisng the same example from the local dask setup, the event chosen is storm Babet which hit the Danish and Northern coast of Germany at the 20<sup>th</sup> of October 2023 [Wikipedia](https://en.wikipedia.org/wiki/Storm_Babet). We target an area around Zingst at the Baltic coast of Northern Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_flood_mapper import flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2023-10-11/2023-10-25\"\n",
    "bbox = [12.3, 54.3, 13.1, 54.6]\n",
    "fd = flood.probability(bbox=bbox, datetime=time_range).compute()\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "\n",
    "\n",
    "fd.hvplot.image(\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    rasterize=True,\n",
    "    geo=True,\n",
    "    tiles=True,\n",
    "    project=True,\n",
    "    frame_height=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to shutdown the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close(shutdown=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask-flood-mapper-z0eq0g_n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
